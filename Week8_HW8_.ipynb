{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODYz6gLmec2+ffXlRSy96z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanvisht/DS-Bootcamp-Assignments/blob/main/Week8_HW8_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "p4E5tZCEHmDQ",
        "outputId": "2ffdce0e-4e74-432c-d1d1-2724f9fb278e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-52b9979bbd38>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-52b9979bbd38>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Logistic Regression:\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "Logistic Regression:\n",
        "1. Try different thresholds for predictions and analyze metrics:\n",
        "By default, predictions are made with a threshold of\n",
        "0.5\n",
        "0.5 (probability\n",
        ">\n",
        "0.5\n",
        ">0.5 predicts class 1).\n",
        "Use predict_proba to obtain probabilities, and vary thresholds (e.g., 0.3, 0.4, 0.5, 0.6, etc.).\n",
        "For each threshold:\n",
        "Compute Accuracy, Precision, and Recall.\n",
        "Observe how these metrics vary:\n",
        "Lower thresholds often increase Recall but reduce Precision.\n",
        "Higher thresholds often improve Precision but lower Recall.\n",
        "2. Repeat the analysis for other target columns:\n",
        "If you have multiple binary or multi-class columns as targets, perform the same threshold analysis for each one.\n",
        "This helps identify if some targets are more sensitive to threshold changes than others.\n",
        "3. Fit a Logistic Regression Model on all features:\n",
        "Preprocessing:\n",
        "Normalize numerical features (e.g., StandardScaler or MinMaxScaler).\n",
        "Perform one-hot encoding for categorical features.\n",
        "Train a Logistic Regression model on all features using LogisticRegression from sklearn.\n",
        "4. Plot ROC Curves for each model:\n",
        "For each target column, compute the True Positive Rate (TPR) and False Positive Rate (FPR) using roc_curve.\n",
        "Plot the ROC curve and calculate the AUC score using roc_auc_score.\n",
        "Compare the ROC curves across models to evaluate their performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Clustering:\n",
        "1. Repeat clustering for different values of\n",
        "ùëò\n",
        "k:\n",
        "Run the K-Means algorithm for various\n",
        "ùëò\n",
        "k values (e.g., 2 to 10).\n",
        "Compute the following for each\n",
        "ùëò\n",
        "k:\n",
        "Inertia: Sum of squared distances of points to their nearest cluster center.\n",
        "Silhouette Score: Measures how well-separated clusters are. Higher is better.\n",
        "2. How do inertia and silhouette scores change?\n",
        "Inertia decreases as\n",
        "ùëò\n",
        "k increases because clusters become smaller and tighter.\n",
        "Silhouette Score:\n",
        "Typically increases up to an optimal\n",
        "ùëò\n",
        "k, then decreases as clusters become too small or overlap.\n",
        "3. What if you don't scale your features?\n",
        "Without scaling, features with larger ranges dominate the clustering process.\n",
        "This can lead to biased clusters and poor silhouette scores.\n",
        "Always scale features before clustering unless the feature units and ranges are comparable.\n",
        "4. Is there a 'right'\n",
        "ùëò\n",
        "k? Why or why not?\n",
        "There is no single \"right\"\n",
        "ùëò\n",
        "k. The choice depends on:\n",
        "The Elbow Method: Look for the point where inertia decreases significantly.\n",
        "Silhouette Score: Choose\n",
        "ùëò\n",
        "k with the highest score.\n",
        "Domain Knowledge: Sometimes\n",
        "ùëò\n",
        "k is guided by practical considerations.\n",
        "Clustering is exploratory, and the \"best\"\n",
        "ùëò\n",
        "k may vary depending on the dataset and the problem being solved."
      ],
      "metadata": {
        "id": "ecrcz8_VHoFk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}